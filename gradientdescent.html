<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gradient Descent Demo</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body class="bg-gray-100 flex items-start justify-center h-screen p-4">

    <div class="flex w-full max-w-7xl">
        <!-- Sidebar -->
        <div class="bg-white p-6 rounded-lg shadow-lg w-1/3 mr-4">
            <h2 class="text-xl font-bold mb-4">What is Gradient Descent?</h2>
            <p class="mb-4">
                Gradient Descent is an optimization algorithm used to minimize the loss function in a machine learning
                model.
                It works by iteratively adjusting the model's parameters (in this case, the weight and bias) to find the
                values that result in the lowest possible loss.
            </p>

            <h3 class="text-lg font-bold mb-2">Key Concepts:</h3>
            <ul class="list-disc list-inside mb-4">
                <li><strong>Loss Function:</strong> Measures how far off the model's predictions are from the actual
                    values.
                    In this demo, we're using Mean Squared Error (MSE) as the loss function.</li>
                <li><strong>Gradient:</strong> The slope or direction of change in the loss function. It tells us how to
                    adjust
                    the weight and bias to reduce the loss.</li>
                <li><strong>Learning Rate:</strong> A small number that determines the step size for each iteration of
                    gradient descent.
                    A smaller learning rate means smaller steps and more iterations, while a larger learning rate means
                    bigger steps but can
                    overshoot the minimum.</li>
            </ul>

            <h3 class="text-lg font-bold mb-2">How it Works:</h3>
            <p>
                The algorithm starts with initial guesses for the weight and bias, often set to zero. It then calculates
                the
                gradient of the loss function with respect to each parameter. The weight and bias are updated in the
                direction
                that decreases the loss, using the formula:
            </p>
            <p class="bg-gray-200 p-2 my-2 rounded">New Weight \( w_{\text{new}} = w_{\text{old}} - \eta \cdot
                \frac{\partial L}{\partial w} \)</p>
            <p class="bg-gray-200 p-2 my-2 rounded">New Bias \( b_{\text{new}} = b_{\text{old}} - \eta \cdot
                \frac{\partial L}{\partial b} \)</p>
            <p>
                This process repeats for a specified number of iterations or until the loss converges to a minimum
                value.
            </p>
            <p class="mb-4">
                The "Optimal Regression Line" shown on the chart represents the best possible fit using all the data
                points. The gradient
                descent algorithm tries to approximate this line by minimizing the loss through iterative updates.
            </p>

            <h3 class="text-lg font-bold mb-2">Explanation of Symbols:</h3>
            <ul class="list-disc list-inside">
                <li><strong>\( w \):</strong> The weight parameter of the model. It determines how much influence the
                    number of stop signs has on the travel time.</li>
                <li><strong>\( b \):</strong> The bias parameter of the model. It represents the baseline travel time
                    when the number of stop signs is zero.</li>
                <li><strong>\( \eta \):</strong> The learning rate. This is a small positive number that controls the
                    size of the steps taken to reach the minimum loss.</li>
                <li><strong>\( \frac{\partial L}{\partial w} \):</strong> The gradient of the loss function with respect
                    to the weight. It shows how much the loss would change with a small change in weight.</li>
                <li><strong>\( \frac{\partial L}{\partial b} \):</strong> The gradient of the loss function with respect
                    to the bias. It shows how much the loss would change with a small change in bias.</li>
                <li><strong>\( L \):</strong> The loss function. In this case, it is the Mean Squared Error (MSE), which
                    measures the average squared difference between the predicted travel times and the actual travel
                    times.</li>
            </ul>
        </div>

        <!-- Chart Section -->
        <div class="bg-white p-6 rounded-lg shadow-lg w-2/3">
            <h1 class="text-2xl font-bold mb-4">Gradient Descent Demo</h1>
            <p class="mb-4">This demo shows how gradient descent works by training a linear model to predict travel time
                based on the number of stop signs.</p>

            <canvas id="chart" class="mb-4"></canvas>

            <div class="mb-4">
                <p id="weightDisplay">Weight: 0</p>
                <p id="optweightDisplay">Optimal Weight: 0</p>
                <p id="biasDisplay">Bias: 0</p>
                <p id="optbiasDisplay">Optimal Bias: 0</p>
                <p id="lossDisplay">Loss: 0</p>
            </div>

            <button id="startButton" class="bg-blue-500 text-white px-4 py-2 rounded">Start Gradient Descent</button>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script>
        const ctx = document.getElementById('chart').getContext('2d');
        const data = {
            labels: Array.from({ length: 12 }, (_, i) => i + 1),
            datasets: [{
                label: 'Actual Travel Time (minutes)',
                data: [14, 15, 16, 15, 17, 18, 19, 20, 22, 23, 24, 26],
                borderColor: 'rgb(255, 99, 132)',
                backgroundColor: 'rgba(255, 99, 132, 0.2)',
                type: 'line',
            }, {
                label: 'Model Prediction (minutes)',
                data: Array(12).fill(0),
                borderColor: 'rgb(54, 162, 235)',
                backgroundColor: 'rgba(54, 162, 235, 0.2)',
                type: 'line',
            }, {
                label: 'Optimal Regression Line',
                data: [],
                borderColor: 'rgb(75, 192, 192)',
                borderDash: [10, 5],
                fill: false,
                type: 'line',
            }]
        };

        const chart = new Chart(ctx, {
            type: 'scatter',
            data: data,
            options: {
                scales: {
                    x: {
                        title: {
                            display: true,
                            text: 'Number of Stop Signs'
                        }
                    },
                    y: {
                        title: {
                            display: true,
                            text: 'Travel Time (minutes)'
                        }
                    }
                }
            }
        });

        const stopSigns = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12];
        const actualTimes = [14, 15, 16, 15, 17, 18, 19, 20, 22, 23, 24, 26];
        let weight = 0;
        let bias = 0;
        const learningRate = 0.01;
        const iterations = 100;

        function calculateLoss() {
            let loss = 0;
            for (let i = 0; i < stopSigns.length; i++) {
                const prediction = weight * stopSigns[i] + bias;
                loss += (actualTimes[i] - prediction) ** 2;
            }
            return loss / stopSigns.length;
        }

        function updateWeightsAndBias() {
            let weightGradient = 0;
            let biasGradient = 0;

            for (let i = 0; i < stopSigns.length; i++) {
                const prediction = weight * stopSigns[i] + bias;
                weightGradient += -2 * stopSigns[i] * (actualTimes[i] - prediction);
                biasGradient += -2 * (actualTimes[i] - prediction);
            }

            weight -= (weightGradient / stopSigns.length) * learningRate;
            bias -= (biasGradient / stopSigns.length) * learningRate;
        }

        function updateDisplay(loss) {
            document.getElementById('weightDisplay').textContent = `Weight: ${weight.toFixed(4)}`;
            document.getElementById('biasDisplay').textContent = `Bias: ${bias.toFixed(4)}`;
            document.getElementById('lossDisplay').textContent = `Loss: ${loss.toFixed(4)}`;
        }

        function calculateOptimalRegressionLine() {
            const n = stopSigns.length;
            const sumX = stopSigns.reduce((a, b) => a + b, 0);
            const sumY = actualTimes.reduce((a, b) => a + b, 0);
            const sumXY = stopSigns.reduce((sum, x, i) => sum + x * actualTimes[i], 0);
            const sumXX = stopSigns.reduce((sum, x) => sum + x * x, 0);

            const optimalWeight = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);
            const optimalBias = (sumY - optimalWeight * sumX) / n;

            const minX = Math.min(...stopSigns);
            const maxX = Math.max(...stopSigns);
            const minY = optimalWeight * minX + optimalBias;
            const maxY = optimalWeight * maxX + optimalBias;

            chart.data.datasets[2].data = [
                { x: minX, y: minY },
                { x: maxX, y: maxY }
            ];
            document.getElementById('optweightDisplay').textContent = `Optimal Weight: ${optimalWeight.toFixed(4)}`;
            document.getElementById('optbiasDisplay').textContent = `Optimal Bias: ${optimalBias.toFixed(4)}`;
            chart.update();
        }

        async function gradientDescent() {
            for (let i = 0; i < iterations; i++) {
                updateWeightsAndBias();
                const loss = calculateLoss();
                updateDisplay(loss);

                const predictions = stopSigns.map(x => weight * x + bias);
                chart.data.datasets[1].data = predictions;

                chart.update();

                await new Promise(resolve => setTimeout(resolve, 20)); // Slow down the loop for visualization
            }
        }

        document.getElementById('startButton').addEventListener('click', gradientDescent);

        // Calculate the static regression line when the page loads
        calculateOptimalRegressionLine();
    </script>
</body>

</html>